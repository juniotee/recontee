cat > apply_fix.sh <<'EOS'
#!/usr/bin/env bash
set -euo pipefail

# Caminho base (raiz do projeto)
BASE="$(pwd)"

echo "[1/5] Backup dos arquivos-alvo…"
mkdir -p .backup_fix
for f in pyproject.toml src/recontee/steps/content.py src/recontee/cli.py; do
  if [ -f "$f" ]; then cp -a "$f" ".backup_fix/${f//\//_}"; fi
done

echo "[2/5] Atualizando 'src/recontee/steps/content.py' (Katana + GAU/PSL)…"
mkdir -p src/recontee/steps
cat > src/recontee/steps/content.py <<'PY'
from __future__ import annotations
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import shutil, subprocess, os, json
from typing import Iterable
from rich.console import Console
from ..utils import run, ensure_dir
import tldextract  # PSL para extrair domínio registrável

console = Console()

def _bin(path: str, fallback: str | None = None) -> str | None:
    p = shutil.which(path)
    if p:
        return p
    if fallback:
        cand = str(Path.home() / "go" / "bin" / fallback)
        if Path(cand).exists():
            return cand
    return None

def _write_dedup(lines: Iterable[str], dest: Path) -> int:
    uniq = sorted(set(s.strip() for s in lines if s and s.strip()))
    ensure_dir(dest.parent)
    dest.write_text("\n".join(uniq), encoding="utf-8")
    return len(uniq)

def _katana_supports(katana_bin: str, flag: str) -> bool:
    """Checa se a versão do katana suporta um flag (via -h)."""
    try:
        res = subprocess.run([katana_bin, "-h"], capture_output=True, text=True, timeout=5)
        helptext = (res.stdout or "") + (res.stderr or "")
        return f" {flag}" in helptext or f"{flag} " in helptext or f"{flag}\n" in helptext
    except Exception:
        return False

def katana_from_list(hosts_file: Path, outdir: Path, threads: int = 80, depth: int = 2) -> Path:
    """Roda Katana em URLs vivos; detecta flags suportados dinamicamente."""
    katana = _bin("katana", "katana")
    urls_out = outdir / "urls" / "katana.txt"
    if not katana:
        console.print("[yellow]katana não encontrado. Pulando.[/yellow]")
        urls_out.write_text("", encoding="utf-8")
        return urls_out

    raw_json = outdir / "urls" / "katana_raw.jsonl"
    ensure_dir(urls_out.parent)
    console.log("4) katana…")

    cmd = [
        katana, "-silent", "-list", str(hosts_file),
        "-depth", str(depth), "-jc", "-aff",
        "-timeout", "20", "-no-color",
        "-threads", str(threads)
    ]
    # Adiciona apenas se a versão suportar
    if _katana_supports(katana, "-max-redirects"):
        cmd += ["-max-redirects", "3"]
    if _katana_supports(katana, "-retries"):
        cmd += ["-retries", "2"]
    if _katana_supports(katana, "-rate-limit"):
        cmd += ["-rate-limit", "1000"]
    if os.environ.get("HTTP_PROXY") and _katana_supports(katana, "-http-proxy"):
        cmd += ["-http-proxy", os.environ["HTTP_PROXY"]]

    lines = list(run(cmd))
    raw_json.write_text("\n".join(lines), encoding="utf-8")

    urls = []
    for ln in lines:
        try:
            obj = json.loads(ln)
            req = obj.get("request") or {}
            u = req.get("url")
            if isinstance(u, str) and u.startswith(("http://", "https://")):
                urls.append(u)
        except Exception:
            pass

    n = _write_dedup(urls, urls_out)
    if n == 0:
        console.print("[yellow]Katana retornou 0 URLs.[/yellow]")
    else:
        console.log(f"   URLs katana: {n}")
    return urls_out

def _gau_one(domain: str) -> list[str]:
    gau = _bin("gau", "gau")
    if not gau:
        return []
    cmd = [gau, "-subs", "--providers", "wayback,commoncrawl,otx"]
    try:
        proc = subprocess.run(cmd, input=domain.encode(), capture_output=True, timeout=180)
        if proc.returncode != 0:
            return []
        out = proc.stdout.decode(errors="ignore").splitlines()
        out = [l.strip() for l in out if domain in l]
        return out
    except Exception:
        return []

def gau_from_subs(subs_file: Path, outdir: Path, max_workers: int = 8) -> Path:
    """Roda GAU usando domínio registrável (PSL), para *.com.br etc."""
    gau = _bin("gau", "gau")
    urls_out = outdir / "urls" / "gau.txt"
    ensure_dir(urls_out.parent)
    if not gau:
        console.print("[yellow]gau não encontrado. Pulando.[/yellow]")
        urls_out.write_text("", encoding="utf-8")
        return urls_out

    console.log("5) gau…")
    subs = [l.strip() for l in subs_file.read_text(encoding="utf-8").splitlines() if l.strip()]
    if not subs:
        urls_out.write_text("", encoding="utf-8")
        return urls_out

    bases: set[str] = set()
    for s in subs:
        ext = tldextract.extract(s)
        if ext.registered_domain:
            bases.add(ext.registered_domain)

    results: list[str] = []
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(_gau_one, b): b for b in sorted(bases)}
        for f in as_completed(futs):
            try:
                results.extend(f.result() or [])
            except Exception:
                pass

    n = _write_dedup(results, urls_out)
    if n == 0:
        console.print("[yellow]GAU retornou 0 URLs.[/yellow]")
    else:
        console.log(f"   URLs gau: {n}")
    return urls_out

def merge_urls(outdir: Path) -> Path:
    """Une katana + gau em urls/all_urls.txt (deduplicado)."""
    all_out = outdir / "urls" / "all_urls.txt"
    parts = []
    for p in [outdir / "urls" / "katana.txt", outdir / "urls" / "gau.txt"]:
        if p.exists():
            parts += p.read_text(encoding="utf-8").splitlines()
    n = _write_dedup(parts, all_out)
    console.log(f"   URLs pré-bruteforce (katana+gau): {n}")
    return all_out
PY

echo "[3/5] Atualizando 'src/recontee/cli.py' (fallback no relatório final)…"
cat > src/recontee/cli.py <<'PY'
import typer, yaml, shutil, subprocess, os
from pathlib import Path
from rich.console import Console
from rich import print
from .pipeline import Context
from .utils import ensure_dir
from .steps import subenum, webprobe, content, bruteforce, dnsresolve, ports

app = typer.Typer(help="Recontee – unified reconnaissance pipeline.")
console = Console()

def _version_of(bin_name: str) -> str:
    try:
        res = subprocess.run([bin_name, "-version"], capture_output=True, text=True, timeout=5)
        if res.returncode != 0:
            res = subprocess.run([bin_name, "--version"], capture_output=True, text=True, timeout=5)
        line = (res.stdout or res.stderr or "").splitlines()[0] if (res.stdout or res.stderr) else ""
        return line.strip()
    except Exception:
        return ""

def assert_prereqs():
    """Verify that required binaries exist in PATH."""
    bins = ["subfinder","amass","dnsx","naabu","httprobe","httpx","katana","gau","ffuf","jq","curl"]
    missing = [b for b in bins if shutil.which(b) is None]
    if missing:
        console.print(f"[red]Missing binaries:[/red] {', '.join(missing)}")
        console.print("Install them with scripts/install_tools.sh and ensure they are on PATH.")
        raise SystemExit(1)
    console.print("[green]✓ All binaries found.[/green]")

@app.command()
def healthcheck():
    """Check installation and connectivity."""
    assert_prereqs()
    console.print("[bold cyan]Versions[/bold cyan]")
    for b in ["subfinder","amass","dnsx","naabu","httprobe","httpx","katana","gau","ffuf"]:
        ver = _version_of(b)
        console.print(f"[green]✓[/green] {b}: [dim]{ver}[/dim]")
    console.print("[bold cyan]\\nConnectivity[/bold cyan]")
    try:
        subprocess.run(["curl","-Is","https://github.com","-m","5"], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        console.print("[green]✓[/green] curl -> github.com OK")
    except Exception:
        console.print("[red]✗[/red] curl failed")

@app.command()
def run(
    target: str = typer.Argument(..., help="Target domain"),
    config: Path = typer.Option("config.yaml", help="YAML config file"),
    resolvers: Path = typer.Option(None, help="Resolvers file"),
    resume: bool = typer.Option(False, help="Resume when possible"),
    force: bool = typer.Option(False, help="Force re-run of steps"),
    proxy: str = typer.Option(None, help="HTTP proxy, e.g., http://127.0.0.1:8080"),
    rl_per_host: int = typer.Option(None, help="ffuf rate limit per host")
):
    """Execute full pipeline."""
    assert_prereqs()
    cfg = yaml.safe_load(Path(config).read_text(encoding="utf-8"))
    outdir = ensure_dir(Path(cfg.get("outputs","out")) / target)
    ctx = Context(target, outdir, cfg.get("threads",80), Path(cfg.get("wordlist")))
    steps_cfg = cfg.get("steps", {})
    ffuf_cfg = cfg.get("ffuf", {})

    if proxy:
        os.environ["HTTP_PROXY"] = proxy
        os.environ["HTTPS_PROXY"] = proxy
        console.print(f"[yellow]Proxy set: {proxy}[/yellow]")

    print(f"[bold cyan]Target:[/bold cyan] {target}")
    print(f"[bold cyan]Wordlist:[/bold cyan] {ctx.wordlist}")

    # 1) Subdomain enumeration
    if steps_cfg.get("subfinder", True):
        subenum.subfinder(target, outdir)
    if steps_cfg.get("amass", True):
        subenum.amass_passive(target, outdir)
    subs = subenum.merge(outdir)
    subs_count = sum(1 for _ in subs.read_text(encoding="utf-8").splitlines() if _)
    print(f"[green]Unique subdomains:[/green] {subs_count}")
    if subs_count == 0:
        subenum.crtsh_fallback(target, outdir)
        subs = subenum.merge(outdir)
        subs_count = sum(1 for _ in subs.read_text(encoding="utf-8").splitlines() if _)
        print(f"[green]Unique subdomains after fallback:[/green] {subs_count}")
        if subs_count == 0:
            print("[yellow]No subdomains found. Exiting.[/yellow]")
            return

    # 2) dnsx
    subs_resolved = dnsresolve.dnsx_filter(subs, outdir, threads=ctx.threads, resolvers=resolvers, force=force)
    subr_count = sum(1 for _ in subs_resolved.read_text(encoding="utf-8").splitlines() if _)
    print(f"[green]Subdomains that resolve (DNS):[/green] {subr_count}")
    if subr_count == 0:
        print("[yellow]No resolvable subdomains. Exiting.[/yellow]")
        return

    # 3) naabu + httpx/httprobe
    naabu_ports = ports.naabu_scan(subs_resolved, outdir, threads=10000, top_ports=1000, rate=12000, retries=1, timeout=1200) if steps_cfg.get("naabu", True) else None
    hosts = webprobe.webprobe_with_httprobe(subs_resolved, outdir, ctx.threads, naabu_ports_file=naabu_ports)
    hosts_count = sum(1 for _ in hosts.read_text(encoding="utf-8").splitlines() if _)
    print(f"[green]HTTP(s) live hosts:[/green] {hosts_count}")
    if hosts_count == 0:
        print("[yellow]No HTTP(s) hosts. Skipping katana/gau/ffuf to avoid noise.[/yellow]")
        steps_cfg["katana"] = False
        steps_cfg["gau"] = False
        steps_cfg["ffuf"] = False

    # 4) katana
    if steps_cfg.get("katana", True):
        content.katana_from_list(hosts, outdir, ctx.threads, depth=2)

    # 5) gau
    if steps_cfg.get("gau", True):
        content.gau_from_subs(subs, outdir)

    # 6) merge katana+gau
    all_urls = content.merge_urls(outdir)

    # 7) ffuf
    if steps_cfg.get("ffuf", True):
        bruteforce.ffuf_multi(
            hosts, ctx.wordlist, outdir,
            threads=ffuf_cfg.get("threads", 20),
            rate_limit=rl_per_host,
            extensions=ffuf_cfg.get("extensions", ""),
            allowed=ffuf_cfg.get("allowed_status", "200,204,301,302,307,308"),
            max_workers=ffuf_cfg.get("max_workers", 6),
            maxtime=ffuf_cfg.get("maxtime", 300),
            maxtime_job=ffuf_cfg.get("maxtime_job", 60),
        )
        ff = outdir / "ffuf" / "ffuf_found.txt"
    else:
        ff = outdir / "ffuf" / "ffuf_found.txt"

    # Final report (inclui hosts vivos como fallback)
    final = outdir / "report" / "urls_final.txt"
    final.parent.mkdir(parents=True, exist_ok=True)
    union: set[str] = set()
    hosts_file = outdir / "web" / "hosts.txt"
    for p in [all_urls, ff, hosts_file]:
        if p.exists():
            for line in p.read_text(encoding="utf-8").splitlines():
                s = line.strip()
                if s:
                    union.add(s)
    final.write_text("\n".join(sorted(union)), encoding="utf-8")
    print(f"[bold green]Done! Final report:[/bold green] {final}")
    print(f"[green]Total collected URLs:[/green] {len(union)}")

if __name__ == "__main__":
    app()
PY

echo "[4/5] Garantindo dependência 'tldextract' no Poetry…"
if command -v poetry >/dev/null 2>&1; then
  poetry add -n tldextract || true
  poetry install -n
else
  echo "[aviso] Poetry não encontrado. Instale via ./scripts/install_tools.sh ou use pip manualmente:"
  echo "       pip install tldextract"
fi

echo "[5/5] Concluído. Arquivos atualizados e dependências instaladas."
echo "     Backups criados em ./.backup_fix/"
EOS

chmod +x apply_fix.sh
